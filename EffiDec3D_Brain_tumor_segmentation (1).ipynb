{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WI5GHLAynQs9",
        "outputId": "073b0cdd-5bbe-49a0-96b3-31378747ca11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opendatasets in /usr/local/lib/python3.12/dist-packages (0.1.22)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from opendatasets) (4.67.1)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.12/dist-packages (from opendatasets) (1.7.4.5)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from opendatasets) (8.3.1)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (6.3.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (2025.11.12)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (3.4.4)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (3.11)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (5.29.5)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (2.9.0.post0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (8.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (2.32.4)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (75.2.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (1.17.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (1.3)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (2.5.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (0.5.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install opendatasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import opendatasets as od\n",
        "od.download(\"https://www.kaggle.com/datasets/mateuszbuda/lgg-mri-segmentation/data\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "avK9F6UbztLK",
        "outputId": "ecb7d42f-5599-416b-8c2d-64b1bf928e57"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping, found downloaded files in \"./lgg-mri-segmentation\" (use force=True to force download)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# LIBRARIES\n",
        "# ============================================================\n",
        "\n",
        "import os\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use(\"ggplot\")\n",
        "%matplotlib inline\n",
        "\n",
        "import cv2\n",
        "from glob import glob\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "# ============================================================\n",
        "# PARAMETERS\n",
        "# ============================================================\n",
        "\n",
        "im_width = 256\n",
        "im_height = 256\n",
        "\n",
        "mask_files = glob('/content/lgg-mri-segmentation/kaggle_3m/*/*_mask*')\n",
        "train_files = [i.replace('_mask','') for i in mask_files]\n",
        "\n",
        "df = pd.DataFrame({\"filename\": train_files, \"mask\": mask_files})\n",
        "\n",
        "def positiv_negativ_diagnosis(mask_path):\n",
        "    value = np.max(cv2.imread(mask_path))\n",
        "    return 1 if value > 0 else 0\n",
        "\n",
        "df[\"diagnosis\"] = df[\"mask\"].apply(positiv_negativ_diagnosis)\n",
        "\n",
        "df_train, df_test = train_test_split(df, test_size=0.1, random_state=42)\n",
        "df_train, df_val = train_test_split(df_train, test_size=0.2, random_state=42)\n",
        "\n",
        "# ============================================================\n",
        "# DATA GENERATOR\n",
        "# ============================================================\n",
        "\n",
        "def adjust_data(img, mask):\n",
        "    img = img / 255.\n",
        "    mask = mask / 255.\n",
        "    mask[mask > 0.5] = 1\n",
        "    mask[mask <= 0.5] = 0\n",
        "    return img, mask\n",
        "\n",
        "def train_generator(df, batch_size=16, aug_dict={}):\n",
        "    # Oversample positive masks\n",
        "    pos_df = df[df.diagnosis==1]\n",
        "    neg_df = df[df.diagnosis==0]\n",
        "    df_balanced = pd.concat([neg_df, pos_df.sample(len(neg_df), replace=True)])\n",
        "\n",
        "    image_datagen = ImageDataGenerator(**aug_dict)\n",
        "    mask_datagen = ImageDataGenerator(**aug_dict)\n",
        "\n",
        "    image_gen = image_datagen.flow_from_dataframe(\n",
        "        df_balanced, x_col=\"filename\", class_mode=None,\n",
        "        color_mode=\"rgb\", target_size=(im_height,im_width),\n",
        "        batch_size=batch_size, seed=42\n",
        "    )\n",
        "\n",
        "    mask_gen = mask_datagen.flow_from_dataframe(\n",
        "        df_balanced, x_col=\"mask\", class_mode=None,\n",
        "        color_mode=\"grayscale\", target_size=(im_height,im_width),\n",
        "        batch_size=batch_size, seed=42\n",
        "    )\n",
        "\n",
        "    for img, mask in zip(image_gen, mask_gen):\n",
        "        img, mask = adjust_data(img, mask)\n",
        "        yield img, mask\n",
        "\n",
        "val_gen = train_generator(df_val, batch_size=16, aug_dict={})\n",
        "test_gen = train_generator(df_test, batch_size=16, aug_dict={})\n",
        "\n",
        "# ============================================================\n",
        "# METRICS AND LOSS\n",
        "# ============================================================\n",
        "\n",
        "def dice_coef(y_true, y_pred, smooth=1):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (2.*intersection + smooth)/(K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
        "\n",
        "def dice_loss(y_true, y_pred):\n",
        "    return 1 - dice_coef(y_true, y_pred)\n",
        "\n",
        "def bce_dice_loss(y_true, y_pred):\n",
        "    bce = tf.keras.losses.BinaryCrossentropy()(y_true, y_pred)\n",
        "    return bce + dice_loss(y_true, y_pred)\n",
        "\n",
        "def iou(y_true, y_pred, smooth=1):\n",
        "    intersection = K.sum(y_true * y_pred)\n",
        "    union = K.sum(y_true + y_pred) - intersection\n",
        "    return (intersection + smooth)/(union + smooth)\n",
        "\n",
        "# ============================================================\n",
        "# MODEL ARCHITECTURE (~4M PARAMS)\n",
        "# ============================================================\n",
        "\n",
        "def dynamic_selector(x, reduction=8):\n",
        "    channels = x.shape[-1]\n",
        "    se = GlobalAveragePooling2D()(x)\n",
        "    se = Dense(channels//reduction, activation='relu')(se)\n",
        "    se = Dense(channels, activation='sigmoid')(se)\n",
        "    se = Reshape((1,1,channels))(se)\n",
        "    return Multiply()([x, se])\n",
        "\n",
        "def nas_decoder_block(x, skip, filters):\n",
        "    c1 = Conv2D(filters,3,padding=\"same\",activation=\"relu\")(x)\n",
        "    c2 = SeparableConv2D(filters,3,padding=\"same\",activation=\"relu\")(x)\n",
        "    concat = Concatenate()([c1,c2])\n",
        "\n",
        "    w = GlobalAveragePooling2D()(concat)\n",
        "    w = Dense(2, activation=\"softmax\")(w)\n",
        "    w = Reshape((1,1,2))(w)\n",
        "\n",
        "    f1, f2 = Lambda(lambda t: tf.split(t,2,axis=-1))(concat)\n",
        "    selected = w[...,0:1]*f1 + w[...,1:2]*f2\n",
        "\n",
        "    skip = dynamic_selector(skip)\n",
        "    return Concatenate()([selected, skip])\n",
        "\n",
        "def enc_block(x, filters):\n",
        "    x = Conv2D(filters,3,padding=\"same\",activation=\"relu\")(x)\n",
        "    x = Conv2D(filters,3,padding=\"same\",activation=\"relu\")(x)\n",
        "    skip = x\n",
        "    x = MaxPooling2D()(x)\n",
        "    return x, skip\n",
        "\n",
        "def EffiDec3D_Medium(input_shape=(256,256,3), filters=[32,64,128,256]):\n",
        "    inputs = Input(input_shape)\n",
        "    x, s1 = enc_block(inputs, filters[0])\n",
        "    x, s2 = enc_block(x, filters[1])\n",
        "    x, s3 = enc_block(x, filters[2])\n",
        "\n",
        "    x = Conv2D(filters[3],3,padding=\"same\",activation=\"relu\")(x)\n",
        "\n",
        "    x = UpSampling2D()(x)\n",
        "    x = nas_decoder_block(x, s3, filters[2])\n",
        "    x = UpSampling2D()(x)\n",
        "    x = nas_decoder_block(x, s2, filters[1])\n",
        "    x = UpSampling2D()(x)\n",
        "    x = nas_decoder_block(x, s1, filters[0])\n",
        "\n",
        "    outputs = Conv2D(1,1,activation=\"sigmoid\")(x)\n",
        "    return Model(inputs, outputs, name=\"EffiDec3D_Medium\")\n",
        "\n",
        "# ============================================================\n",
        "# TRAINING\n",
        "# ============================================================\n",
        "\n",
        "model = EffiDec3D_Medium((256,256,3))\n",
        "model.compile(\n",
        "    optimizer=Adam(3e-4),\n",
        "    loss=bce_dice_loss,\n",
        "    metrics=[\"binary_accuracy\", dice_coef, iou]\n",
        ")\n",
        "\n",
        "callbacks = [ModelCheckpoint(\"EffiDec3D_Medium_best.keras\", save_best_only=True)]\n",
        "\n",
        "train_gen = train_generator(df_train, batch_size=16, aug_dict={\n",
        "    \"rotation_range\":0.2,\n",
        "    \"width_shift_range\":0.05,\n",
        "    \"height_shift_range\":0.05,\n",
        "    \"zoom_range\":0.05,\n",
        "    \"horizontal_flip\":True\n",
        "})\n",
        "\n",
        "history = model.fit(\n",
        "    train_gen,\n",
        "    steps_per_epoch=len(df_train)//16,\n",
        "    validation_data=val_gen,\n",
        "    validation_steps=len(df_val)//16,\n",
        "    epochs=50,\n",
        "    callbacks=callbacks\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zdg1XmCTKBz6",
        "outputId": "cbe355bd-a489-460f-db1e-9fa303fdcbd2"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3710 validated image filenames.\n",
            "Found 3710 validated image filenames.\n",
            "Epoch 1/50\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 485ms/step - binary_accuracy: 0.9814 - dice_coef: 0.1250 - iou: 0.0763 - loss: 1.1386Found 896 validated image filenames.\n",
            "Found 896 validated image filenames.\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 572ms/step - binary_accuracy: 0.9814 - dice_coef: 0.1259 - iou: 0.0769 - loss: 1.1369 - val_binary_accuracy: 0.9890 - val_dice_coef: 0.4761 - val_iou: 0.3296 - val_loss: 0.5806\n",
            "Epoch 2/50\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 733ms/step - binary_accuracy: 0.9870 - dice_coef: 0.5092 - iou: 0.3556 - loss: 0.5529 - val_binary_accuracy: 0.9892 - val_dice_coef: 0.6340 - val_iou: 0.4749 - val_loss: 0.4200\n",
            "Epoch 3/50\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 474ms/step - binary_accuracy: 0.9874 - dice_coef: 0.5530 - iou: 0.3979 - loss: 0.5124 - val_binary_accuracy: 0.9907 - val_dice_coef: 0.6411 - val_iou: 0.4803 - val_loss: 0.4026\n",
            "Epoch 4/50\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 468ms/step - binary_accuracy: 0.9888 - dice_coef: 0.5572 - iou: 0.4095 - loss: 0.5006 - val_binary_accuracy: 0.9914 - val_dice_coef: 0.6376 - val_iou: 0.4798 - val_loss: 0.4092\n",
            "Epoch 5/50\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 470ms/step - binary_accuracy: 0.9888 - dice_coef: 0.5905 - iou: 0.4363 - loss: 0.4697 - val_binary_accuracy: 0.9921 - val_dice_coef: 0.6207 - val_iou: 0.4673 - val_loss: 0.4318\n",
            "Epoch 6/50\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 475ms/step - binary_accuracy: 0.9901 - dice_coef: 0.5945 - iou: 0.4440 - loss: 0.4638 - val_binary_accuracy: 0.9922 - val_dice_coef: 0.7075 - val_iou: 0.5544 - val_loss: 0.3318\n",
            "Epoch 7/50\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 499ms/step - binary_accuracy: 0.9911 - dice_coef: 0.6507 - iou: 0.4988 - loss: 0.3971 - val_binary_accuracy: 0.9925 - val_dice_coef: 0.7215 - val_iou: 0.5696 - val_loss: 0.3181\n",
            "Epoch 8/50\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 804ms/step - binary_accuracy: 0.9908 - dice_coef: 0.5985 - iou: 0.4562 - loss: 0.4510 - val_binary_accuracy: 0.9924 - val_dice_coef: 0.6979 - val_iou: 0.5453 - val_loss: 0.3394\n",
            "Epoch 9/50\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 469ms/step - binary_accuracy: 0.9925 - dice_coef: 0.7170 - iou: 0.5663 - loss: 0.3206 - val_binary_accuracy: 0.9933 - val_dice_coef: 0.7346 - val_iou: 0.5902 - val_loss: 0.3003\n",
            "Epoch 10/50\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 463ms/step - binary_accuracy: 0.9904 - dice_coef: 0.6416 - iou: 0.5020 - loss: 0.4147 - val_binary_accuracy: 0.9935 - val_dice_coef: 0.7145 - val_iou: 0.5699 - val_loss: 0.3194\n",
            "Epoch 11/50\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 464ms/step - binary_accuracy: 0.9917 - dice_coef: 0.6722 - iou: 0.5283 - loss: 0.3721 - val_binary_accuracy: 0.9909 - val_dice_coef: 0.6722 - val_iou: 0.5147 - val_loss: 0.3733\n",
            "Epoch 12/50\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 465ms/step - binary_accuracy: 0.9908 - dice_coef: 0.6825 - iou: 0.5386 - loss: 0.3667 - val_binary_accuracy: 0.9923 - val_dice_coef: 0.7307 - val_iou: 0.5832 - val_loss: 0.3104\n",
            "Epoch 13/50\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 468ms/step - binary_accuracy: 0.9914 - dice_coef: 0.6623 - iou: 0.5260 - loss: 0.3874 - val_binary_accuracy: 0.9936 - val_dice_coef: 0.7361 - val_iou: 0.5894 - val_loss: 0.3000\n",
            "Epoch 14/50\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 467ms/step - binary_accuracy: 0.9923 - dice_coef: 0.7128 - iou: 0.5753 - loss: 0.3311 - val_binary_accuracy: 0.9939 - val_dice_coef: 0.7669 - val_iou: 0.6277 - val_loss: 0.2662\n",
            "Epoch 15/50\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 464ms/step - binary_accuracy: 0.9925 - dice_coef: 0.7020 - iou: 0.5671 - loss: 0.3416 - val_binary_accuracy: 0.9936 - val_dice_coef: 0.7212 - val_iou: 0.5801 - val_loss: 0.3113\n",
            "Epoch 16/50\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 465ms/step - binary_accuracy: 0.9915 - dice_coef: 0.6781 - iou: 0.5401 - loss: 0.3696 - val_binary_accuracy: 0.9924 - val_dice_coef: 0.7383 - val_iou: 0.5906 - val_loss: 0.2934\n",
            "Epoch 17/50\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 467ms/step - binary_accuracy: 0.9911 - dice_coef: 0.6945 - iou: 0.5565 - loss: 0.3550 - val_binary_accuracy: 0.9938 - val_dice_coef: 0.7539 - val_iou: 0.6117 - val_loss: 0.2766\n",
            "Epoch 18/50\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 466ms/step - binary_accuracy: 0.9926 - dice_coef: 0.7328 - iou: 0.5995 - loss: 0.3083 - val_binary_accuracy: 0.9948 - val_dice_coef: 0.7739 - val_iou: 0.6388 - val_loss: 0.2522\n",
            "Epoch 19/50\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 462ms/step - binary_accuracy: 0.9920 - dice_coef: 0.6892 - iou: 0.5515 - loss: 0.3589 - val_binary_accuracy: 0.9937 - val_dice_coef: 0.7229 - val_iou: 0.5768 - val_loss: 0.3118\n",
            "Epoch 20/50\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 463ms/step - binary_accuracy: 0.9925 - dice_coef: 0.6964 - iou: 0.5662 - loss: 0.3473 - val_binary_accuracy: 0.9946 - val_dice_coef: 0.7900 - val_iou: 0.6577 - val_loss: 0.2392\n",
            "Epoch 21/50\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 462ms/step - binary_accuracy: 0.9937 - dice_coef: 0.7507 - iou: 0.6202 - loss: 0.2844 - val_binary_accuracy: 0.9947 - val_dice_coef: 0.7752 - val_iou: 0.6405 - val_loss: 0.2522\n",
            "Epoch 22/50\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 465ms/step - binary_accuracy: 0.9926 - dice_coef: 0.7389 - iou: 0.6074 - loss: 0.3055 - val_binary_accuracy: 0.9947 - val_dice_coef: 0.7990 - val_iou: 0.6711 - val_loss: 0.2288\n",
            "Epoch 23/50\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 463ms/step - binary_accuracy: 0.9931 - dice_coef: 0.7545 - iou: 0.6289 - loss: 0.2864 - val_binary_accuracy: 0.9949 - val_dice_coef: 0.7776 - val_iou: 0.6488 - val_loss: 0.2474\n",
            "Epoch 24/50\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 471ms/step - binary_accuracy: 0.9921 - dice_coef: 0.7295 - iou: 0.6066 - loss: 0.3199 - val_binary_accuracy: 0.9950 - val_dice_coef: 0.8061 - val_iou: 0.6815 - val_loss: 0.2229\n",
            "Epoch 25/50\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 460ms/step - binary_accuracy: 0.9944 - dice_coef: 0.7892 - iou: 0.6746 - loss: 0.2427 - val_binary_accuracy: 0.9947 - val_dice_coef: 0.7837 - val_iou: 0.6543 - val_loss: 0.2453\n",
            "Epoch 26/50\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 478ms/step - binary_accuracy: 0.9928 - dice_coef: 0.7490 - iou: 0.6232 - loss: 0.2961 - val_binary_accuracy: 0.9945 - val_dice_coef: 0.7825 - val_iou: 0.6472 - val_loss: 0.2468\n",
            "Epoch 27/50\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 467ms/step - binary_accuracy: 0.9948 - dice_coef: 0.7722 - iou: 0.6573 - loss: 0.2555 - val_binary_accuracy: 0.9951 - val_dice_coef: 0.8232 - val_iou: 0.7034 - val_loss: 0.2014\n",
            "Epoch 28/50\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 468ms/step - binary_accuracy: 0.9930 - dice_coef: 0.7494 - iou: 0.6301 - loss: 0.2923 - val_binary_accuracy: 0.9949 - val_dice_coef: 0.7874 - val_iou: 0.6567 - val_loss: 0.2392\n",
            "Epoch 29/50\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 467ms/step - binary_accuracy: 0.9930 - dice_coef: 0.7605 - iou: 0.6417 - loss: 0.2844 - val_binary_accuracy: 0.9955 - val_dice_coef: 0.8212 - val_iou: 0.7005 - val_loss: 0.2001\n",
            "Epoch 30/50\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 464ms/step - binary_accuracy: 0.9934 - dice_coef: 0.7511 - iou: 0.6354 - loss: 0.2887 - val_binary_accuracy: 0.9949 - val_dice_coef: 0.7988 - val_iou: 0.6717 - val_loss: 0.2273\n",
            "Epoch 31/50\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 468ms/step - binary_accuracy: 0.9944 - dice_coef: 0.7619 - iou: 0.6491 - loss: 0.2715 - val_binary_accuracy: 0.9951 - val_dice_coef: 0.8032 - val_iou: 0.6780 - val_loss: 0.2198\n",
            "Epoch 32/50\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 806ms/step - binary_accuracy: 0.9944 - dice_coef: 0.7856 - iou: 0.6680 - loss: 0.2462 - val_binary_accuracy: 0.9949 - val_dice_coef: 0.8229 - val_iou: 0.7019 - val_loss: 0.2027\n",
            "Epoch 33/50\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 450ms/step - binary_accuracy: 0.9957 - dice_coef: 0.8421 - iou: 0.7323 - loss: 0.1788 - val_binary_accuracy: 0.9956 - val_dice_coef: 0.8206 - val_iou: 0.7033 - val_loss: 0.2005\n",
            "Epoch 34/50\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 466ms/step - binary_accuracy: 0.9938 - dice_coef: 0.7815 - iou: 0.6721 - loss: 0.2573 - val_binary_accuracy: 0.9952 - val_dice_coef: 0.8294 - val_iou: 0.7116 - val_loss: 0.1929\n",
            "Epoch 35/50\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 464ms/step - binary_accuracy: 0.9942 - dice_coef: 0.7503 - iou: 0.6508 - loss: 0.2858 - val_binary_accuracy: 0.9961 - val_dice_coef: 0.8439 - val_iou: 0.7346 - val_loss: 0.1744\n",
            "Epoch 36/50\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 466ms/step - binary_accuracy: 0.9944 - dice_coef: 0.7702 - iou: 0.6647 - loss: 0.2655 - val_binary_accuracy: 0.9959 - val_dice_coef: 0.8467 - val_iou: 0.7365 - val_loss: 0.1731\n",
            "Epoch 37/50\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 463ms/step - binary_accuracy: 0.9941 - dice_coef: 0.7931 - iou: 0.6843 - loss: 0.2449 - val_binary_accuracy: 0.9948 - val_dice_coef: 0.7889 - val_iou: 0.6547 - val_loss: 0.2377\n",
            "Epoch 38/50\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 466ms/step - binary_accuracy: 0.9940 - dice_coef: 0.7664 - iou: 0.6580 - loss: 0.2702 - val_binary_accuracy: 0.9954 - val_dice_coef: 0.8203 - val_iou: 0.6992 - val_loss: 0.2054\n",
            "Epoch 39/50\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 464ms/step - binary_accuracy: 0.9931 - dice_coef: 0.7710 - iou: 0.6602 - loss: 0.2736 - val_binary_accuracy: 0.9960 - val_dice_coef: 0.8410 - val_iou: 0.7296 - val_loss: 0.1790\n",
            "Epoch 40/50\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 460ms/step - binary_accuracy: 0.9943 - dice_coef: 0.7858 - iou: 0.6731 - loss: 0.2490 - val_binary_accuracy: 0.9949 - val_dice_coef: 0.7765 - val_iou: 0.6443 - val_loss: 0.2501\n",
            "Epoch 41/50\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 464ms/step - binary_accuracy: 0.9951 - dice_coef: 0.7938 - iou: 0.6903 - loss: 0.2356 - val_binary_accuracy: 0.9960 - val_dice_coef: 0.8567 - val_iou: 0.7519 - val_loss: 0.1618\n",
            "Epoch 42/50\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 461ms/step - binary_accuracy: 0.9948 - dice_coef: 0.7899 - iou: 0.6864 - loss: 0.2408 - val_binary_accuracy: 0.9961 - val_dice_coef: 0.8495 - val_iou: 0.7405 - val_loss: 0.1691\n",
            "Epoch 43/50\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 465ms/step - binary_accuracy: 0.9942 - dice_coef: 0.8078 - iou: 0.7059 - loss: 0.2301 - val_binary_accuracy: 0.9965 - val_dice_coef: 0.8598 - val_iou: 0.7563 - val_loss: 0.1572\n",
            "Epoch 44/50\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 806ms/step - binary_accuracy: 0.9950 - dice_coef: 0.8070 - iou: 0.7165 - loss: 0.2277 - val_binary_accuracy: 0.9961 - val_dice_coef: 0.8675 - val_iou: 0.7673 - val_loss: 0.1515\n",
            "Epoch 45/50\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 465ms/step - binary_accuracy: 0.9968 - dice_coef: 0.8816 - iou: 0.7901 - loss: 0.1327 - val_binary_accuracy: 0.9964 - val_dice_coef: 0.8650 - val_iou: 0.7643 - val_loss: 0.1517\n",
            "Epoch 46/50\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 448ms/step - binary_accuracy: 0.9960 - dice_coef: 0.8567 - iou: 0.7673 - loss: 0.1671 - val_binary_accuracy: 0.9963 - val_dice_coef: 0.8542 - val_iou: 0.7472 - val_loss: 0.1628\n",
            "Epoch 47/50\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 465ms/step - binary_accuracy: 0.9955 - dice_coef: 0.7972 - iou: 0.6967 - loss: 0.2291 - val_binary_accuracy: 0.9962 - val_dice_coef: 0.8559 - val_iou: 0.7513 - val_loss: 0.1619\n",
            "Epoch 48/50\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 463ms/step - binary_accuracy: 0.9940 - dice_coef: 0.7971 - iou: 0.6999 - loss: 0.2427 - val_binary_accuracy: 0.9962 - val_dice_coef: 0.8603 - val_iou: 0.7572 - val_loss: 0.1576\n",
            "Epoch 49/50\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 464ms/step - binary_accuracy: 0.9940 - dice_coef: 0.7954 - iou: 0.6996 - loss: 0.2466 - val_binary_accuracy: 0.9966 - val_dice_coef: 0.8734 - val_iou: 0.7768 - val_loss: 0.1415\n",
            "Epoch 50/50\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 462ms/step - binary_accuracy: 0.9952 - dice_coef: 0.8043 - iou: 0.7142 - loss: 0.2262 - val_binary_accuracy: 0.9969 - val_dice_coef: 0.8787 - val_iou: 0.7860 - val_loss: 0.1350\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ============================================================\n",
        "# MODEL PARAMETERS, GFLOPs & MEMORY\n",
        "# ============================================================\n",
        "\n",
        "# Parameters\n",
        "total_params = model.count_params()\n",
        "print(f\"Total Parameters: {total_params/1e6:.2f}M\")\n",
        "\n",
        "# Memory usage\n",
        "def memory_usage(model, batch=1):\n",
        "    weights_bytes = model.count_params() * 4\n",
        "    weights_mb = weights_bytes / (1024**2)\n",
        "\n",
        "    activation_bytes = 0\n",
        "    for layer in model.layers:\n",
        "        try:\n",
        "            out_shape = layer.output_shape\n",
        "        except:\n",
        "            continue\n",
        "        if isinstance(out_shape, list):\n",
        "            continue\n",
        "        if None in out_shape:\n",
        "            continue\n",
        "        activation_bytes += np.prod(out_shape)*4\n",
        "    activation_mb = activation_bytes / (1024**2)\n",
        "    return weights_mb, activation_mb, weights_mb + activation_mb\n",
        "\n",
        "weights_mb, activations_mb, total_mb = memory_usage(model)\n",
        "print(f\"Weight Memory: {weights_mb:.2f} MB\")\n",
        "print(f\"Total Estimated Memory: {total_mb:.2f} MB\")\n",
        "\n",
        "# GFLOPs calculation\n",
        "def get_gflops(model, input_shape=(1,256,256,3)):\n",
        "    inputs = tf.random.uniform(input_shape)\n",
        "    @tf.function\n",
        "    def forward(x): return model(x)\n",
        "    concrete_func = forward.get_concrete_function(inputs)\n",
        "\n",
        "    from tensorflow.python.profiler.model_analyzer import profile\n",
        "    from tensorflow.python.profiler.option_builder import ProfileOptionBuilder\n",
        "\n",
        "    profiler_options = ProfileOptionBuilder.float_operation()\n",
        "    graph_info = profile(concrete_func.graph, options=profiler_options)\n",
        "\n",
        "    flops = graph_info.total_float_ops\n",
        "    return flops/1e9\n",
        "\n",
        "gflops = get_gflops(model)\n",
        "print(f\"GFLOPs: {gflops:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H4pZceLeKFAi",
        "outputId": "780ff26e-8a0f-4cb7-85aa-db8d235d0a4c"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Parameters: 1.13M\n",
            "Weight Memory: 4.30 MB\n",
            "Total Estimated Memory: 4.30 MB\n",
            "GFLOPs: 19.269\n"
          ]
        }
      ]
    }
  ]
}